{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/SendilCannane/Neural-Network/blob/master/SimpleNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "-yZnJS_OvIz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "bc222f94-e9db-4b75-c821-1ae71547a713"
      },
      "cell_type": "code",
      "source": [
        "#%matplotlib.inline\n",
        "\n",
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import IPython\n",
        "print(IPython.sys_info())"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'commit_hash': 'b467d487e',\n",
            " 'commit_source': 'installation',\n",
            " 'default_encoding': 'UTF-8',\n",
            " 'ipython_path': '/usr/local/lib/python3.6/dist-packages/IPython',\n",
            " 'ipython_version': '5.5.0',\n",
            " 'os_name': 'posix',\n",
            " 'platform': 'Linux-4.14.65+-x86_64-with-Ubuntu-18.04-bionic',\n",
            " 'sys_executable': '/usr/bin/python3',\n",
            " 'sys_platform': 'linux',\n",
            " 'sys_version': '3.6.6 (default, Sep 12 2018, 18:26:19) \\n'\n",
            "                '[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H39RHAPhzj2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "52d71be1-f977-418c-fce7-8e292403a13d"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "data_mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-272144b5fb56>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wU_8OzIg3ROG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_train = data_mnist.train\n",
        "data_test = data_mnist.test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCwV0MKb3Up0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a0d8001-ec7d-4c6a-bb72-093857a93e9a"
      },
      "cell_type": "code",
      "source": [
        "data_test.cls = np.argmax(data_test.labels, axis=1)\n",
        "data_test.cls[0:5]\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "MS0x1n9f5W5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34a34e87-a1da-4ead-ff67-c31afb188d45"
      },
      "cell_type": "code",
      "source": [
        "data_train.images.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "xRoJoFp85qWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a79dcf37-8fe3-4a64-a6af-c82ed3ea3550"
      },
      "cell_type": "code",
      "source": [
        "data_train.labels.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "tNGnUEiJ5vFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97276238-d51d-468c-da94-e423d0b994a9"
      },
      "cell_type": "code",
      "source": [
        "data_test.images.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "WRX62NVk52hn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb193d80-7b55-4169-a10d-4f2cd6e494a1"
      },
      "cell_type": "code",
      "source": [
        "data_test.labels.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "rGZd7jb_579G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.2\n",
        "num_steps = 500\n",
        "batch_size = 128\n",
        "display_step = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AX4lNzSbB52m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_h1_nodes = 256\n",
        "num_h2_nodes = 256\n",
        "num_inputs = 784 #data_test.images.shape (10000, 784)\n",
        "num_classes = 10 #data_test.labels.shape (10000, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77wlBbv0Cyx-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=tf.placeholder(tf.float32, [None,num_inputs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYz1NaYWD9wQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y=tf.placeholder(tf.float32,[None,num_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eZScESsPEHqo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#weights and biases\n",
        "\n",
        "weights = {\n",
        "    'h1w' : tf.Variable(tf.random_normal([num_inputs, num_h1_nodes])),\n",
        "    'h2w' : tf.Variable(tf.random_normal([num_h1_nodes, num_h2_nodes])),\n",
        "    'out' : tf.Variable(tf.random_normal([num_h2_nodes, num_classes]))\n",
        "    \n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'h1b1': tf.Variable(tf.random_normal([num_h1_nodes])),\n",
        "    'h2b2': tf.Variable(tf.random_normal([num_h2_nodes])),\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SYJxhN2ycqgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PijKQpnSCO80",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model\n",
        "def neural_net(x):\n",
        "    # Hidden fully connected layer with 256 neurons\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1w']), biases['h1b1'])\n",
        "    # Hidden fully connected layer with 256 neurons\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2w']), biases['h2b2'])\n",
        "    # Output fully connected layer with a neuron for each class\n",
        "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
        "    return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0oAZEqquIRf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logits = neural_net(x)\n",
        "\n",
        "# Define loss and optimizer\n",
        "# In order to use the cross-entropy to guide the optimization of the model's variables \n",
        "# we need a single scalar value, so we simply take the average of the cross-entropy for all the image classifications.\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "# We need a few more performance measures to display the progress to the user.\n",
        "# This is a vector of booleans whether the predicted class equals the true class of each image.\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "\n",
        "\n",
        "#This calculates the classification accuracy by first type-casting the vector of \n",
        "#booleans to floats, so that False becomes 0 and True becomes 1, and then calculating the average of these numbers\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I9IAITJ2dOAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = tf.nn.softmax(logits)\n",
        "y_pred_cls = tf.argmax(y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L0EmCvCGRV6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "322cc565-023e-4925-fdaa-e45b983fa0d9"
      },
      "cell_type": "code",
      "source": [
        "# Start training with train data\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    for step in range(1, num_steps+1):\n",
        "      #Split the data to be trained as batch_x and batch_y\n",
        "        batch_x, batch_y = data_train.next_batch(batch_size)\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={x: batch_x, Y: batch_y})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={x: batch_x,\n",
        "                                                                 Y: batch_y})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "\n",
        "    print(\"Training Finished!\")\n",
        "    print(\"Testing Accuracy:\", \\\n",
        "        sess.run(accuracy, feed_dict={x: data_test.images,\n",
        "                                      Y: data_test.labels}))\n",
        "    \n",
        "    # Get the true classifications for the test-set.\n",
        "    cls_true = data_test.cls\n",
        "    #data_test.cls = np.argmax(data_test.labels, axis=1)\n",
        "    # Get the predicted classifications for the test-set.\n",
        "    cls_pred = sess.run(y_pred_cls, feed_dict={x: data_test.images,Y: data_test.labels})\n",
        "    #cls_pred = sess.run(test_pred, feed_dict={x: data_test.images,\n",
        "     #                                 Y: data_test.labels})\n",
        "      \n",
        "    cm = confusion_matrix(y_true=cls_true,\n",
        "                          y_pred=cls_pred)\n",
        "\n",
        "    # Print the confusion matrix as text.\n",
        "    print (\"***********Confusion matrix************\")\n",
        "    print(cm)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Minibatch Loss= 8031.0151, Training Accuracy= 0.359\n",
            "Step 100, Minibatch Loss= 330.7074, Training Accuracy= 0.820\n",
            "Step 200, Minibatch Loss= 222.9307, Training Accuracy= 0.859\n",
            "Step 300, Minibatch Loss= 60.9252, Training Accuracy= 0.867\n",
            "Step 400, Minibatch Loss= 102.4662, Training Accuracy= 0.883\n",
            "Step 500, Minibatch Loss= 33.4525, Training Accuracy= 0.914\n",
            "Training Finished!\n",
            "Testing Accuracy: 0.8637\n",
            "***********Confusion matrix************\n",
            "[[ 916    0    4    1    3    5   18   16   16    1]\n",
            " [   0 1098    6    1    0    1    4    2   23    0]\n",
            " [   9   17  890   39   17    3   17    8   30    2]\n",
            " [   6    5   20  811    0  115    3    9   37    4]\n",
            " [   0    9    6    6  916    5   12    4   14   10]\n",
            " [  15    5    6   29    8  714   18   12   81    4]\n",
            " [  19    9    9    0   10   13  876    0   22    0]\n",
            " [   3   17   26   27    7    3    0  918    2   25]\n",
            " [   3   36    8   45   10   17    4   25  821    5]\n",
            " [   6   11    2   18  184   21    1   70   19  677]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n84eMQEBTcQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}